{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi all, this is some of the work I did previously when looking at driver behavior as it relates to crashes/injuries. Much of this work could be updated to include more recent years: 2020, 2021, and 2022. Of course, this will come with new issues in the data analysis given the effects of the pandemic. \n",
    "\n",
    "This is based on our internal Python library and datasets we use in our database--but these (or very similar versions) should also exist for you all to access given our data-sharing for this project. If something does not make sense, Seth should be able to troubleshoot. I am also available in a limited way for follow up. These are just some ideas for analysis and draft code--feel free to disregard. \n",
    "\n",
    "Best, \n",
    "Chris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Notes\n",
    "\n",
    "Analysis:\n",
    "- We no longer receive all PDO (Propery Damage Only) crashes as of 2020 from NYPD. Any analysis using 2020-onwards data could compare C injuries crashes (or C and B injuries crashes) versus severe (A) injuries crashes versus fatality crashes to get a better idea of severity. \n",
    "- This includes road network (intersection/block) crashes as well as highway crashes. These can be separated as they are somewhat different in nature. Furthermore, speed cameras only exist on the local level, so there is a different sample (potentially) when thinking about people getting in highway crashes (more out of state?) versus local crashes and how that interacts with the violation data.\n",
    "\n",
    "Data Notes: \n",
    "- Where I use 'working.speed_camera_vio' -- this is just the DOF Speed Camera/Parking Violations filtered on only **PHTO SCHOOL ZN SPEED VIOLATION**\n",
    "- Where I use 'working.rlc_vio' -- this is just the DOF Speed Camera/Parking Violations filtered on only **FAILURE TO STOP AT RED LIGHT**\n",
    "- Where I use 'working.vio_all' (deprecated) -- this is the combination of these two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('BehaviorStudyInitialResults_20230405.xlsx')\n",
    "db = pysqldb.DbConnect(type='pg',server='dotdevrhpgsql01', database='ris', allow_temp_tables=True, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pysqldb.DbConnect(type='pg',server='dotdevrhpgsql01', database='ris', allow_temp_tables=True, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_sql = pysqldb.DbConnect(type='MS', server='dotgissql01', database='Fatality', ldap=True, quiet=True)\n",
    "forms_sql = pysqldb.DbConnect(type='MS', server='dot55sql01', database='FORMS', user='arcgis', password='arcgis', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Standardized Cleaned Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns non-junk plates\n",
    "\n",
    "Context: there are many plates in the data that are just junk. To try to limit studies to valid plates/licenses, I attempted to remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.table_exists(schema='working', table='cleaned_plates'):\n",
    "    db.dfquery(\"\"\"\n",
    "\n",
    "    drop table if exists working.cleaned_plates; \n",
    "    create table working.cleaned_plates as \n",
    "\n",
    "    select distinct  \n",
    "        lower(plate_num) as plate_num\n",
    "    from \n",
    "        wc_accident_vehicle_f \n",
    "    where\n",
    "        plate_num is not null \n",
    "        and lower(plate_num) not in (\n",
    "            'ladder 1', 'fire', 'usps', 'police', 'uknown', 'not regi', 'bicycle', 'fdny', \n",
    "            'unk', 'unkn', 'unkown', 'unknown', 'none', 'n/a', 'n\\\\a', 'no plate', 'na', \n",
    "            'zzzzzr1', 'zzzzzzum', 'zzz-zzzz', '`', '|||', '|()|', '__', '?', '? ? ?', \n",
    "            '????', '?????', '??????', '???????', '????????', \n",
    "            '///////', '////////', '@*$$|$', '@%^$', '*', '*****', '*******', '', \n",
    "            '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', '&^*@', '+.', '00000.', '000-000-', '00000000', '00000001', '0000000o', \n",
    "            '0000001', '999999999', '000000000', 'na', '99999999', '123456789', '00000000', '9999999999', \n",
    "            '0000000000', '9999999', '000000', '999999', 'exempt', '111111111', 'unk', '0000000', 'none', \n",
    "            '00000000000', 'unknown', '99999999999', '0', '0000', 'pd', '000000000000', '99999', '999999999999', \n",
    "            '00000', '0000000000000', '000', '.', 'p', '999', '9999', '00000000000000', '00000000000000000000',\n",
    "            '178084863', 'e57372256110582', 'xxxxxxxxx', '000000001', 'onfile', '99999999999999', '890463639', \n",
    "            '000000000000000', 'unlicensed', 'policeinvolved', 's', '2', 'left sce', 'engine 2',  'noplate', 'ukn', \n",
    "            'not appl', 'bike', 't')\n",
    "        and not (length(plate_num) = 4 and plate_num like '20%')\n",
    "        and replace(plate_num, '0', '') != ''\n",
    "        and replace(plate_num, '1', '') != ''\n",
    "        and replace(plate_num, '9', '') != ''\n",
    "        and replace(plate_num, 'x', '') != ''\n",
    "        and replace(plate_num, '-', '') != ''\n",
    "        and replace(plate_num, '.', '') != ''\n",
    "        and replace(lower(plate_num), 'z', '') != ''\n",
    "        and replace(lower(plate_num), ' ', '') != '\\\\'\n",
    "        and plate_num not like '%unregist%'\n",
    "        and plate_num not like '%temp%'\n",
    "        and crash_date >= '2017-01-01'\n",
    "\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns non-junk license numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.table_exists(schema='working', table='cleaned_licenses'):\n",
    "\n",
    "    db.dfquery(\"\"\"\n",
    "    drop table if exists working.cleaned_licenses; \n",
    "    create table working.cleaned_licenses as \n",
    "\n",
    "    select distinct  \n",
    "        driver_license_num\n",
    "    from \n",
    "        wc_accident_vehicle_f \n",
    "    where\n",
    "        driver_license_num is not null \n",
    "\n",
    "        and lower(driver_license_num) not in (\n",
    "            'ladder 1', 'fire', 'usps', 'police', 'uknown', 'not regi', 'bicycle', 'fdny', \n",
    "            'unk', 'unkn', 'unkown', 'unknown', 'none', 'n/a', 'n\\\\a', 'no plate', 'na', \n",
    "            'zzzzzr1', 'zzzzzzum', 'zzz-zzzz', '`', '|||', '|()|', '__', '?', '? ? ?', \n",
    "            '????', '?????', '??????', '???????', '????????', \n",
    "            '///////', '////////', '@*$$|$', '@%^$', '*', '*****', '*******', '', \n",
    "            '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', '&^*@', '+.', '00000.', '000-000-', '00000000', '00000001', '0000000o', \n",
    "            '0000001', '999999999', '000000000', 'na', '99999999', '123456789', '00000000', '9999999999', \n",
    "            '0000000000', '9999999', '000000', '999999', 'exempt', '111111111', 'unk', '0000000', 'none', \n",
    "            '00000000000', 'unknown', '99999999999', '0', '0000', 'pd', '000000000000', '99999', '999999999999', \n",
    "            '00000', '0000000000000', '000', '.', 'p', '999', '9999', '00000000000000', '00000000000000000000',\n",
    "            '178084863', 'e57372256110582','000000001', 'onfile', '99999999999999', '890463639', \n",
    "            '000000000000000', 'unlicensed', 'policeinvolved', 's', '2', 'left sce', 'engine 2',  'noplate', 'ukn', 'fd', \n",
    "            'rked', 'nolicense')\n",
    "\n",
    "        and replace(driver_license_num, '1', '') != ''\n",
    "        and replace(driver_license_num, '0', '') != ''\n",
    "        and replace(driver_license_num, '9', '') != ''\n",
    "        and replace(driver_license_num, 'x', '') != ''\n",
    "        and replace(driver_license_num, '-', '') != ''\n",
    "        and replace(driver_license_num, '.', '') != ''\n",
    "        and replace(driver_license_num, '*', '') != ''\n",
    "        and replace(lower(driver_license_num), 'z', '') != ''\n",
    "        and replace(lower(driver_license_num), ' ', '') != '\\\\'\n",
    "        and driver_license_num not like '%unregist%'\n",
    "        and driver_license_num not like '%temp%'\n",
    "        and crash_date >= '2017-01-01'\n",
    "\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns if a plate has a TLC pattern\n",
    "\n",
    "TLC indicators based off of:\n",
    "\n",
    "- TC/YC \n",
    "- Dollar Van plates \n",
    "- Number/letter/number/number/letter\n",
    "- Number/letter/number/number http://www.nyc.gov/html/tlc_medallion_info/html/tlc_lookup.shtml\n",
    "- Letter/letter/number/number/number\n",
    "- Letter/letter/letter/number/number/number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.table_exists('tlc_plate_ind', schema='working'):\n",
    "\n",
    "    db.dfquery(\"\"\"\n",
    "\n",
    "    drop table if exists working.tlc_plate_ind; \n",
    "    create table working.tlc_plate_ind as \n",
    "\n",
    "    select \n",
    "        replace(lower(plate_num), ' ', '') as plate_num,\n",
    "        case \n",
    "            when lower(plate_num) like 't%c' then True \n",
    "            when lower(plate_num) like 'y%c' then True \n",
    "            when lower(plate_num) like 'o%l' then True \n",
    "            when \n",
    "                lower(plate_num) like '%lv' \n",
    "                or lower(plate_num) like '%lv' \n",
    "                or lower(plate_num) like '%lb' \n",
    "                or lower(plate_num) like '%la' \n",
    "                or lower(plate_num) like '%bb' \n",
    "                then True \n",
    "            when lower(plate_num) ~* '^([0-9]){1}([a-z]){1}([0-9]){1}([0-9]){1}([a-z]){1}$' then True\n",
    "            when lower(plate_num) ~* '^([0-9]){1}([a-z]){1}([0-9]){1}([0-9]){1}$' then True \n",
    "            when lower(plate_num) ~* '^([a-z]){1}([a-z]){1}([0-9]){1}([0-9]){1}([0-9]){1}$' then True\n",
    "            when lower(plate_num) ~* '^([a-z]){1}([a-z]){1}([a-z]){1}([0-9]){1}([0-9]){1}([0-9]){1}$' then True\n",
    "            else False \n",
    "        end as tlc_veh \n",
    "    from \n",
    "        wc_accident_vehicle_f \n",
    "\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: the data has a TLC-involved indicator. The license plate is another attempt to identify for-hire vehicles. I thought this could be an important differentiator in driver behavior, and I recommend exploring 'normal' driver and TLC behavior separately, if possible, or at least exploring that possibility.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns single driver plates \n",
    "\n",
    "A plate can have at most one license number associated with it (and nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.table_exists('single_driver_plates', schema='working'):\n",
    "    db.dfquery(\"\"\"\n",
    "\n",
    "    drop table if exists working.single_driver_plates; \n",
    "    create table working.single_driver_plates as \n",
    "\n",
    "    select \n",
    "        replace(lower(ve.plate_num), ' ', '') as plate_num\n",
    "    from \n",
    "        wc_accident_vehicle_f ve\n",
    "    \n",
    "    join \n",
    "        working.cleaned_plates cp  \n",
    "    on \n",
    "        lower(ve.plate_num)=cp.plate_num \n",
    "    \n",
    "    join \n",
    "        working.cleaned_licenses cl \n",
    "    on \n",
    "        ve.driver_license_num=cl.driver_license_num\n",
    "    \n",
    "    where \n",
    "        ve.crash_date >= '2017-01-01'\n",
    "    \n",
    "    group by 1 \n",
    "    \n",
    "    having count(distinct ve.driver_license_num) < 2\n",
    "\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver Demographics \n",
    " - The ris cleaned version of wc_accident_victim_f doesn't have the non-injured parties (for ex., a non-injured driver) \n",
    " - Manually pulling from SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.drop_table('working', 'driver_demo')\n",
    "\n",
    "if not db.table_exists(schema='working', table='driver_demo'):\n",
    "    q = \"\"\"\n",
    "\n",
    "    select \n",
    "        ve.accident_id as crashid,\n",
    "        plate_num, \n",
    "        cast(norm_driver_license_number as nvarchar(max)) as driver_license_num,\n",
    "        VICTIM_AGE, \n",
    "        VICTIM_SEX\n",
    "    from \n",
    "        wc_accident_vehicle_f ve \n",
    "\n",
    "    left join \n",
    "        wc_accident_victim_f vi\n",
    "\n",
    "    on\n",
    "        ve.ACCIDENT_ID=vi.ACCIDENT_ID \n",
    "        and ve.vehicle_num=vi.vehicle_num \n",
    "        and vi.person_role_code='Driver' \n",
    "\n",
    "    where\n",
    "        ve.ACCIDENT_DT >= '2017-01-01'\n",
    "        and ve.ACCIDENT_DT <= '2021-12-31'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pysqldb.sql_to_pg_qry(forms_sql, db, q, dest_schema='working', dest_table='driver_demo') #, encoding='LATIN1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Contributing Factors Yearly Breakdown for Injury Crashes\n",
    "\n",
    "To Do:\n",
    "- Add % diff of category, not just % of all crashes to breakdowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inj_cf = db.dfquery(\"\"\"\n",
    "\n",
    "with cf_breakdown as (\n",
    "    \n",
    "    select  \n",
    "        case \n",
    "            when crash_date between '2017-01-01' and '2017-12-31' then 2017\n",
    "            when crash_date between '2018-01-01' and '2018-12-31' then 2018 \n",
    "            when crash_date between '2019-01-01' and '2019-12-31' then 2019 \n",
    "        end as period, \n",
    "        initcap(cf) as cf, \n",
    "        count(distinct crashid)\n",
    "    from (\n",
    "        select \n",
    "            --GET DISTINCT PERIOD/CF COUNT FOR ALL INJ CRASH \n",
    "            ve.contributing_factor_1 as cf, \n",
    "            ve.crashid, \n",
    "            ve.crash_date\n",
    "        from\n",
    "            wc_accident_vehicle_f ve\n",
    "        join \n",
    "            (select distinct crashid from wc_accident_victim_f where inj_killed='Injured') i \n",
    "        on \n",
    "            i.crashid=ve.crashid\n",
    "        where \n",
    "            crash_date between '2017-01-01' and '2019-12-31'\n",
    "\n",
    "        union \n",
    "\n",
    "        select \n",
    "            --GET DISTINCT PERIOD/CF COUNT FOR ALL INJ CRASH \n",
    "            ve.contributing_factor_2 as cf, \n",
    "            ve.crashid, \n",
    "            ve.crash_date\n",
    "        from\n",
    "            wc_accident_vehicle_f ve\n",
    "        join \n",
    "            (select distinct crashid from wc_accident_victim_f where inj_killed='Injured') i \n",
    "        on \n",
    "            i.crashid=ve.crashid\n",
    "        where \n",
    "            crash_date between '2017-01-01' and '2019-12-31'\n",
    "    ) c\n",
    "    group by 1, 2\n",
    "), \n",
    "\n",
    "period_breakdown as (\n",
    "    --GET DISTINCT PERIOD COUNT FOR ALL INJ CRASH \n",
    "    select \n",
    "        case \n",
    "            when crash_date between '2017-01-01' and '2017-12-31' then 2017\n",
    "            when crash_date between '2018-01-01' and '2018-12-31' then 2018 \n",
    "            when crash_date between '2019-01-01' and '2019-12-31' then 2019 \n",
    "        end as period, \n",
    "        count(distinct a.crashid) as total\n",
    "    from \n",
    "        wc_accident_f a \n",
    "    join \n",
    "        (select distinct crashid from wc_accident_victim_f where inj_killed='Injured') i \n",
    "    on \n",
    "        i.crashid=a.crashid\n",
    "    where \n",
    "        crash_date between '2017-01-01' and '2019-12-31'\n",
    "    group by 1\n",
    ")\n",
    "\n",
    "select \n",
    "    cf.*, t.total\n",
    "from \n",
    "    cf_breakdown cf\n",
    "right join \n",
    "    period_breakdown t\n",
    "on \n",
    "    cf.period=t.period\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Calculate fraction of period's crashes for each contributing factor \n",
    "all_inj_cf['frac'] = all_inj_cf['count']/all_inj_cf['total']*100\n",
    "all_inj_cf = all_inj_cf.pivot(index='cf', columns='period', values='frac').reset_index()\n",
    "\n",
    "# Filter to those that are always > 0.5% of crashes (> 1/200)\n",
    "cols_df = all_inj_cf.set_index('cf').T.min().reset_index()\n",
    "cols = list(cols_df[(cols_df[0] > 0.5) & (~cols_df['cf'].isna())]['cf'])\n",
    "\n",
    "# Aesthetic\n",
    "all_inj_cf = all_inj_cf[all_inj_cf['cf'].isin(cols)]\n",
    "all_inj_cf = all_inj_cf.reset_index(drop=True).rename(columns={\n",
    "        'cf': 'Contributing Factor',\n",
    "}).round(2)\n",
    "\n",
    "all_inj_cf.sort_values(by=2019, ascending=False).to_excel(writer, 'ContributingFactorsYOY', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Contributing Factors for Repeat Vehicles \n",
    "\n",
    "Analysis Idea: look at the contributing factor breakdown for severe injuries and/or fatality crashes and compare those breakdowns to the 'normal' crashes (C injuries only). I attempted to do this here by using repeat vehicles in the crash data as a 'high risk' group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inj_cf = db.dfquery(\"\"\"\n",
    "\n",
    "with multi_plates as (\n",
    "    \n",
    "    select \n",
    "        distinct crashid \n",
    "    from \n",
    "        wc_accident_vehicle_f ve \n",
    "    \n",
    "    join \n",
    "        working.cleaned_plates cp \n",
    "    on \n",
    "        lower(ve.plate_num)=cp.plate_num \n",
    "        \n",
    "    where \n",
    "       replace(lower(ve.plate_num), ' ', '') in ( \n",
    "    \n",
    "        select \n",
    "            replace(lower(ve.plate_num), ' ', '') plate_num\n",
    "\n",
    "        from \n",
    "            wc_accident_vehicle_f ve \n",
    "\n",
    "        join \n",
    "            working.cleaned_plates cp \n",
    "        on \n",
    "            lower(ve.plate_num)=cp.plate_num \n",
    "        \n",
    "        where \n",
    "            ve.crash_date >= '2017-01-01'\n",
    "\n",
    "        group by 1 \n",
    "\n",
    "        having count(distinct ve.crashid) > 1 \n",
    "    \n",
    "    ) \n",
    "), \n",
    "\n",
    "cf_breakdown as (\n",
    "    \n",
    "    select  \n",
    "        case \n",
    "            when crash_date between '2017-01-01' and '2017-12-31' then 2017\n",
    "            when crash_date between '2018-01-01' and '2018-12-31' then 2018 \n",
    "            when crash_date between '2019-01-01' and '2019-12-31' then 2019 \n",
    "        end as period, \n",
    "        cf, \n",
    "        count(distinct crashid)\n",
    "    from (\n",
    "        select \n",
    "            --GET DISTINCT PERIOD/CF COUNT FOR ALL INJ CRASH \n",
    "            initcap(ve.contributing_factor_1) as cf, \n",
    "            ve.crashid, \n",
    "            ve.crash_date\n",
    "        from\n",
    "            wc_accident_vehicle_f ve\n",
    "        join \n",
    "            (select distinct crashid from wc_accident_victim_f where inj_killed='Injured') i \n",
    "        on \n",
    "            i.crashid=ve.crashid\n",
    "        join \n",
    "            wc_accident_f a \n",
    "        on \n",
    "            ve.crashid=a.crashid\n",
    "        join \n",
    "            multi_plates mp \n",
    "        on \n",
    "            mp.crashid=a.crashid\n",
    "        where \n",
    "            ve.crash_date between '2017-01-01' and '2019-12-31'\n",
    "\n",
    "        union \n",
    "\n",
    "        select \n",
    "            --GET DISTINCT PERIOD/CF COUNT FOR ALL INJ CRASH \n",
    "            initcap(ve.contributing_factor_2) as cf, \n",
    "            ve.crashid, \n",
    "            ve.crash_date\n",
    "        from\n",
    "            wc_accident_vehicle_f ve\n",
    "        join \n",
    "            (select distinct crashid from wc_accident_victim_f where inj_killed='Injured') i \n",
    "        on \n",
    "            i.crashid=ve.crashid\n",
    "        join \n",
    "            wc_accident_f a \n",
    "        on \n",
    "            ve.crashid=a.crashid\n",
    "        join \n",
    "            multi_plates mp \n",
    "        on \n",
    "            mp.crashid=a.crashid\n",
    "        where \n",
    "            ve.crash_date between '2017-01-01' and '2019-12-31'\n",
    "    ) c\n",
    "    group by 1, 2\n",
    "), \n",
    "\n",
    "period_breakdown as (\n",
    "    --GET DISTINCT PERIOD COUNT FOR ALL INJ CRASH \n",
    "    select \n",
    "        case \n",
    "            when ve.crash_date between '2017-01-01' and '2017-12-31' then 2017\n",
    "            when ve.crash_date between '2018-01-01' and '2018-12-31' then 2018 \n",
    "            when ve.crash_date between '2019-01-01' and '2019-12-31' then 2019 \n",
    "        end as period, \n",
    "        count(distinct a.crashid) as total\n",
    "    from \n",
    "        wc_accident_f a \n",
    "    join \n",
    "        (select distinct crashid from wc_accident_victim_f where inj_killed='Injured') i \n",
    "    on \n",
    "        i.crashid=a.crashid\n",
    "    join \n",
    "        wc_accident_vehicle_f ve \n",
    "    on \n",
    "        ve.crashid=a.crashid\n",
    "    join \n",
    "        multi_plates mp \n",
    "    on \n",
    "        mp.crashid=a.crashid\n",
    "    where \n",
    "        ve.crash_date between '2017-01-01' and '2019-12-31'\n",
    "    group by 1\n",
    ")\n",
    "\n",
    "select \n",
    "    cf.*, t.total\n",
    "from \n",
    "    cf_breakdown cf\n",
    "right join \n",
    "    period_breakdown t\n",
    "on \n",
    "    cf.period=t.period\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Calculate fraction of period's crashes for each contributing factor \n",
    "all_inj_cf['frac'] = all_inj_cf['count']/all_inj_cf['total']*100\n",
    "all_inj_cf = all_inj_cf.pivot(index='cf', columns='period', values='frac').reset_index()\n",
    "\n",
    "# Filter to those that are always > 0.5% of crashes (> 1/200)\n",
    "cols_df = all_inj_cf.set_index('cf').T.min().reset_index()\n",
    "cols = list(cols_df[(cols_df[0] > 0.5) & (~cols_df['cf'].isna()) & (cols_df['cf'] != 'unspecified')]['cf'])\n",
    "\n",
    "# Aesthetic\n",
    "all_inj_cf = all_inj_cf[all_inj_cf['cf'].isin(cols)]\n",
    "all_inj_cf = all_inj_cf.reset_index(drop=True).rename(columns={\n",
    "        'cf': 'Contributing Factor',\n",
    "}).round(2)\n",
    "\n",
    "all_inj_cf.sort_values(by=2019, ascending=False).to_excel(writer, 'ContributingFactorsRepeat', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Targeted Narrative Keywords in FORMS\n",
    "\n",
    "This was an attempt to see if the narratives were indicating an increase in a variety of phenomena. I would ignore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\" \n",
    "\n",
    "select \n",
    "    date_part('year', crash_date)::int as year, \n",
    "    case \n",
    "        when f.forms_crashid is not null then 'Fatal'\n",
    "        when i.crashid is not null then 'Injury' \n",
    "        else 'PDO' \n",
    "    end as status,\n",
    "    100*count(distinct case when narrative like '% drug%' then a.crashid end)::float/count(*) as drug , \n",
    "    100*count(distinct case when narrative like '% alcohol%' then a.crashid end)::float/count(*) as alcohol, \n",
    "    100*count(distinct case when narrative like '% bac %' then a.crashid end)::float/count(*) as bac , \n",
    "    100*count(distinct case when narrative like '% drunk%' then a.crashid end)::float/count(*) as drunk , \n",
    "    100*count(distinct case when narrative like '% speed%' then a.crashid end)::float/count(*) as speed , \n",
    "    100*count(distinct case when narrative like '% reckless%' then a.crashid end)::float/count(*) as reckless , \n",
    "    100*count(distinct case when narrative like '% phone%' then a.crashid end)::float/count(*) as phone , \n",
    "    100*count(distinct case when narrative like '% medication%' then a.crashid end)::float/count(*) as medication , \n",
    "    100*count(distinct case when narrative like '% unsafe%' then a.crashid end)::float/count(*) as unsafe, \n",
    "    100*count(distinct case when narrative like '% dangerous%' then a.crashid end)::float/count(*) as dangerous , \n",
    "    100*count(distinct case when narrative like '% distract%' then a.crashid end)::float/count(*) as distract, \n",
    "    100*count(distinct case when narrative like '% sleep%' then a.crashid end)::float/count(*) as sleep, \n",
    "    100*count(distinct case when narrative like '% inexperience%' then a.crashid end)::float/count(*) as inexperience, \n",
    "    100*count(distinct case when narrative like '% improper%' then a.crashid end)::float/count(*) as improper , \n",
    "    100*count(distinct case when narrative like '% disregard%' then a.crashid end)::float/count(*) as disregard, \n",
    "    100*count(distinct case when narrative like '% illness%' then a.crashid end)::float/count(*) as illness, \n",
    "    100*count(distinct case when narrative like '% illegal%' then a.crashid end)::float/count(*) as illegal, \n",
    "    100*count(distinct case when narrative like '% headphone%' then a.crashid end)::float/count(*) as headphone, \n",
    "    100*count(distinct case when narrative like '% inattention%' then a.crashid end)::float/count(*) as inattention, \n",
    "    count(*)\n",
    "from \n",
    "    wc_accident_f a \n",
    "left join \n",
    "    (select distinct crashid from wc_accident_victim_f) i \n",
    "on \n",
    "    a.crashid=i.crashid \n",
    "left join \n",
    "    (select distinct forms_crashid from fatal_crash) f \n",
    "on \n",
    "    a.crashid=f.forms_crashid::numeric\n",
    "where \n",
    "    crash_date between '2017-01-01' and '2019-12-31'\n",
    "group by 1, 2 \n",
    "order by 2, 1 \n",
    "\n",
    "\"\"\").round(2).to_excel(writer, 'TargetedKeywordsByCrashType', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Violations Numbers \n",
    "\n",
    "This section simply gets violation counts by year and type of license plate (commercial, passenger, etc.). \n",
    "\n",
    "Reference codes found here: https://dmv.ny.gov/registration/registration-class-codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    date_part('year', issue_date::date)::int as year, \n",
    "    license_type, \n",
    "    count(*) \n",
    "from \n",
    "    working.speed_camera_vio \n",
    "group by \n",
    "    1, 2\n",
    "\n",
    "\"\"\").pivot(index='license_type', columns='year', values='count').sort_values(by=2021, ascending=False).reset_index().to_excel(writer, 'AllPlateViolationsByYearByVehicleType', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at NYS plates only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    date_part('year', issue_date::date)::int as year, \n",
    "    license_type, \n",
    "    count(*) \n",
    "from \n",
    "    working.speed_camera_vio \n",
    "where \n",
    "    state='NY'\n",
    "group by \n",
    "    1, 2\n",
    "\n",
    "\"\"\").pivot(index='license_type', columns='year', values='count').sort_values(by=2021, ascending=False).reset_index().to_excel(writer, 'NYPlateViolationsByYearByVehicleType', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red light camera yearly counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    date_part('year', issue_date::date)::int as year, \n",
    "    license_type, \n",
    "    count(*) \n",
    "\n",
    "from \n",
    "    working.rlc_vio\n",
    "\n",
    "group by \n",
    "    1, 2\n",
    "\n",
    "\"\"\").pivot(index='license_type', columns='year', values='count').sort_values(by=2021, ascending=False).reset_index().to_excel(writer, 'AllPlateRLCViolationsByYearByVehicleType', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLC for NY Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    date_part('year', issue_date::date)::int as year, \n",
    "    license_type, \n",
    "    count(*) \n",
    "\n",
    "from \n",
    "    working.rlc_vio\n",
    "\n",
    "where \n",
    "    state='NY'\n",
    "\n",
    "group by \n",
    "    1, 2\n",
    "\n",
    "\"\"\").pivot(index='license_type', columns='year', values='count').sort_values(by=2021, ascending=False).reset_index().to_excel(writer, 'NYPlateRLCViolationsByYearByVehicleType', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Violations per Plate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at types with a non-negligible number of violations for NY plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_types = set(db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    license_type, \n",
    "    count(*)\n",
    "from\n",
    "    working.speed_camera_vio \n",
    "where\n",
    "    state='NY'\n",
    "group by \n",
    "    1\n",
    "having count(*) > 10000 \n",
    "order by 2 desc\n",
    "\"\"\")['license_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating for RLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_types_rlc = set(db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    license_type, \n",
    "    count(*)\n",
    "from\n",
    "    working.rlc_vio\n",
    "where\n",
    "    state='NY'\n",
    "group by \n",
    "    1\n",
    "having count(*) > 10000 \n",
    "order by 2 desc\n",
    "\"\"\")['license_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the breakdown of the number of violations by plate by plate type for NY plates only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdown = db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    viol_count, \n",
    "    license_type, \n",
    "    count(*)\n",
    "from (\n",
    "    select \n",
    "        license_type,\n",
    "        plate, \n",
    "        count(*) as viol_count \n",
    "\n",
    "    from \n",
    "        working.speed_camera_vio \n",
    "\n",
    "    where \n",
    "        state='NY'\n",
    "\n",
    "    group by \n",
    "        1, 2\n",
    ") pc \n",
    "group by 1, 2\n",
    "order by 2, 1 asc \n",
    "\"\"\")\n",
    "\n",
    "breakdown[breakdown['license_type'].isin(relevant_types)].pivot(index='license_type', columns='viol_count', values='count').fillna(0).T.reset_index().to_excel(writer, 'NYPlatesViolationsOccurrenceAllTime', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown above for RLC only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdown_rlc = db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    viol_count, \n",
    "    license_type, \n",
    "    count(*)\n",
    "from (\n",
    "    select \n",
    "        license_type,\n",
    "        plate, \n",
    "        count(*) as viol_count \n",
    "\n",
    "    from \n",
    "        working.rlc_vio\n",
    "\n",
    "    where \n",
    "        state='NY'\n",
    "\n",
    "    group by \n",
    "        1, 2\n",
    ") pc \n",
    "group by 1, 2\n",
    "order by 2, 1 asc \n",
    "\"\"\")\n",
    "\n",
    "breakdown_rlc[breakdown_rlc['license_type'].isin(relevant_types_rlc)].pivot(index='license_type', columns='viol_count', values='count').fillna(0).T.reset_index().to_excel(writer, 'NYPlatesViolationsOccurrenceAllTimeRLC', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Above Repeated for 2020, 2019 Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdown = db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    viol_count, \n",
    "    license_type, \n",
    "    count(*)\n",
    "from (\n",
    "    select \n",
    "        license_type,\n",
    "        plate, \n",
    "        count(*) as viol_count \n",
    "\n",
    "    from \n",
    "        working.speed_camera_vio \n",
    "\n",
    "    where \n",
    "        state='NY'\n",
    "        and date_part('year', issue_date::date)::int = 2020\n",
    "\n",
    "    group by \n",
    "        1, 2\n",
    ") pc \n",
    "group by 1, 2\n",
    "order by 2, 1 asc \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "breakdown[breakdown['license_type'].isin(relevant_types)].pivot(index='license_type', columns='viol_count', values='count').fillna(0).T.reset_index().to_excel(writer, 'NYPlatesViolationsOccurrence2020', index=False)\n",
    "\n",
    "breakdown = db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    viol_count, \n",
    "    license_type, \n",
    "    count(*)\n",
    "from (\n",
    "    select \n",
    "        license_type,\n",
    "        plate, \n",
    "        count(*) as viol_count \n",
    "\n",
    "    from \n",
    "        working.speed_camera_vio \n",
    "\n",
    "    where \n",
    "        state='NY'\n",
    "        and date_part('year', issue_date::date)::int = 2019\n",
    "\n",
    "    group by \n",
    "        1, 2\n",
    ") pc \n",
    "group by 1, 2\n",
    "order by 2, 1 asc \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "breakdown[breakdown['license_type'].isin(relevant_types)].pivot(index='license_type', columns='viol_count', values='count').fillna(0).T.reset_index().to_excel(writer, 'NYPlatesViolationsOccurrence2019', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 breakdown RLC\n",
    "breakdown = db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    viol_count, \n",
    "    license_type, \n",
    "    count(*)\n",
    "from (\n",
    "    select \n",
    "        license_type,\n",
    "        plate, \n",
    "        count(*) as viol_count \n",
    "\n",
    "    from \n",
    "        working.rlc_vio\n",
    "\n",
    "    where \n",
    "        state='NY'\n",
    "        and date_part('year', issue_date::date)::int = 2020\n",
    "\n",
    "    group by \n",
    "        1, 2\n",
    ") pc \n",
    "group by 1, 2\n",
    "order by 2, 1 asc \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "breakdown[breakdown['license_type'].isin(relevant_types)].pivot(index='license_type', columns='viol_count', values='count').fillna(0).T.to_excel(writer, 'NYPlatesViolationsOccurrenceRLC2020', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 breakdown RLC\n",
    "breakdown = db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    viol_count, \n",
    "    license_type, \n",
    "    count(*)\n",
    "from (\n",
    "    select \n",
    "        license_type,\n",
    "        plate, \n",
    "        count(*) as viol_count \n",
    "\n",
    "    from \n",
    "        working.rlc_vio\n",
    "\n",
    "    where \n",
    "        state='NY'\n",
    "        and date_part('year', issue_date::date)::int = 2019\n",
    "\n",
    "    group by \n",
    "        1, 2\n",
    ") pc \n",
    "group by 1, 2\n",
    "order by 2, 1 asc \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "breakdown[breakdown['license_type'].isin(relevant_types)].pivot(index='license_type', columns='viol_count', values='count').fillna(0).T.to_excel(writer, 'NYPlatesViolationsOccurrenceRLC2019', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Violation Involvement across Crash Types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given vehicle in a crash (vehicle_crash), gets the previous number of violations \n",
    "\n",
    "Notes: \n",
    "- Right now, limits time-frame to 2019 only (**should update or try other timeframes**)\n",
    "- To explore: highway vs. non-highway breakdown\n",
    "- To explore: number of violations in a given time frame (1Y prior crash, 2Y, etc.)\n",
    "- To explore: below limits to only vehicle type car/suv but this could be removed or changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_vio = db.dfquery(\"\"\"\n",
    "\n",
    "select distinct \n",
    "    concat(ve.vehicle_num, '-', ve.crashid) as vehicle_crash,\n",
    "    case \n",
    "        when fl.forms_crashid is not null then 'Fatal'\n",
    "        when inj.crashid is not null then 'Injury'\n",
    "        else 'PDO' \n",
    "    end as type,\n",
    "    count(distinct v_all.*) as vio_num_prior\n",
    "from \n",
    "    wc_accident_vehicle_f ve \n",
    "\n",
    "join\n",
    "    wc_accident_f a \n",
    "on \n",
    "    ve.crashid=a.crashid \n",
    "    --and a.loc in ('mid', 'int')\n",
    "\n",
    "--JOIN CRASHES TO CLEANED PLATES TO LIMIT \n",
    "join \n",
    "    working.cleaned_plates cp \n",
    "on \n",
    "    lower(ve.plate_num)=cp.plate_num \n",
    "\n",
    "--LIMIT TO NON-TLC ONLY \n",
    "join \n",
    "    working.tlc_plate_ind tlc \n",
    "on \n",
    "    lower(ve.plate_num)=tlc.plate_num \n",
    "    and tlc.tlc_veh='False' \n",
    "\n",
    "left join \n",
    "    (select distinct forms_crashid from fatal_crash) fl\n",
    "on \n",
    "    ve.crashid=fl.forms_crashid::numeric\n",
    "\n",
    "left join \n",
    "    (select distinct crashid from wc_accident_victim_f where inj_killed='injured') inj\n",
    "on \n",
    "    ve.crashid=inj.crashid\n",
    "\n",
    "left join \n",
    "    (select distinct plate, issue_date from working.speed_camera_vio) v_all\n",
    "on \n",
    "    lower(ve.plate_num)=lower(v_all.plate)\n",
    "    and issue_date::date < ve.crash_date::date\n",
    "\n",
    "where \n",
    "    date_part('year', ve.crash_date) = 2019\n",
    "    and plate_state='NY'\n",
    "    and veh_type_general='car/suv'\n",
    "\n",
    "group by 1, 2\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps: \n",
    "- Update data \n",
    "- Remove PDO, switch to C/B Injury, A Injury, Fatality or C/B Injury vs KSI\n",
    "- Explore timeframes\n",
    "\n",
    "Gets those with 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10+ prior violations %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas code to get the number of vehicle-crash incidences where the number of prior violations was 0, 1, ...10+\n",
    "# Broken out by PDO, Injury, Fatal \n",
    "\n",
    "data = {}\n",
    "for typ in ('PDO', 'Injury', 'Fatal'):\n",
    "    data[typ] = {}\n",
    "    for i in range(1, 11):\n",
    "        tmp_df = prev_vio[prev_vio['type'] == typ]\n",
    "        if i == 10:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] >= i])/(len(tmp_df)*1.0)\n",
    "        else:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] == i])/(len(tmp_df)*1.0)\n",
    "\n",
    "pd.DataFrame(data).reset_index().to_excel(writer, 'PastViolationsByCrashType10+', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets those with 0, 1, 2+ prior violations %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas code to get the number of vehicle-crash incidences where the number of prior violations was 0, 1, 2+\n",
    "# Broken out by PDO, Injury, Fatal \n",
    "\n",
    "data = {}\n",
    "for typ in ('PDO', 'Injury', 'Fatal'):\n",
    "    data[typ] = {}\n",
    "    for i in range(1, 3):\n",
    "        tmp_df = prev_vio[prev_vio['type'] == typ]\n",
    "        if i == 2:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] >= i])/(len(tmp_df)*1.0)\n",
    "        else:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] == i])/(len(tmp_df)*1.0)\n",
    "\n",
    "pd.DataFrame(data).reset_index().to_excel(writer, 'PastViolationsByCrashType2+', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above for Red Light Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_vio = db.dfquery(\"\"\"\n",
    "\n",
    "select distinct \n",
    "    concat(ve.vehicle_num, '-', ve.crashid) as vehicle_crash,\n",
    "    case \n",
    "        when fl.forms_crashid is not null then 'Fatal'\n",
    "        when inj.crashid is not null then 'Injury'\n",
    "        else 'PDO' \n",
    "    end as type,\n",
    "    count(distinct v_all.*) as vio_num_prior \n",
    "from \n",
    "    wc_accident_vehicle_f ve \n",
    "\n",
    "join\n",
    "    wc_accident_f a \n",
    "on \n",
    "    ve.crashid=a.crashid \n",
    "    and a.loc in ('mid', 'int')\n",
    "\n",
    "join \n",
    "    working.cleaned_plates cp \n",
    "on \n",
    "    lower(ve.plate_num)=cp.plate_num \n",
    "\n",
    "\n",
    "join \n",
    "    working.tlc_plate_ind tlc \n",
    "on \n",
    "    lower(ve.plate_num)=tlc.plate_num \n",
    "    and tlc.tlc_veh='False' \n",
    "\n",
    "left join \n",
    "    (select distinct forms_crashid from fatal_crash) fl\n",
    "on \n",
    "    ve.crashid=fl.forms_crashid::numeric\n",
    "\n",
    "left join \n",
    "    (select distinct crashid from wc_accident_victim_f where inj_killed='injured') inj\n",
    "on \n",
    "    ve.crashid=inj.crashid\n",
    "\n",
    "left join \n",
    "    (select distinct plate, issue_date from working.rlc_vio) v_all\n",
    "on \n",
    "    lower(ve.plate_num)=lower(v_all.plate)\n",
    "    and issue_date::date < ve.crash_date::date\n",
    "\n",
    "where \n",
    "    date_part('year', ve.crash_date) = 2019\n",
    "    and plate_state='NY'\n",
    "    and veh_type_general='car/suv'\n",
    "\n",
    "group by 1, 2\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for typ in ('PDO', 'Injury', 'Fatal'):\n",
    "    data[typ] = {}\n",
    "    for i in range(1, 11):\n",
    "        tmp_df = prev_vio[prev_vio['type'] == typ]\n",
    "        if i == 10:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] >= i])/(len(tmp_df)*1.0)\n",
    "        else:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] == i])/(len(tmp_df)*1.0)\n",
    "\n",
    "pd.DataFrame(data).reset_index().to_excel(writer, 'RLCPastViolationsByCrashType10+', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for typ in ('PDO', 'Injury', 'Fatal'):\n",
    "    data[typ] = {}\n",
    "    for i in range(1, 3):\n",
    "        tmp_df = prev_vio[prev_vio['type'] == typ]\n",
    "        if i == 2:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] >= i])/(len(tmp_df)*1.0)\n",
    "        else:\n",
    "            data[typ][i] = 100*len(tmp_df[tmp_df['vio_num_prior'] == i])/(len(tmp_df)*1.0)\n",
    "\n",
    "pd.DataFrame(data).reset_index().to_excel(writer, 'RLCPastViolationsByCrashType2+', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.0 Violation Crash Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to do a correlation between the number of crashes and the number of violations. This did not work out because crashes are such a rare event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Contributing Factor Breakdown by Violator Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Analysis Ideas\n",
    "\n",
    "1. Get % breakdown in a timeframe of all injury crashes. \n",
    "2. Show with 1, 2, 5, 10, 20 violation universe of cars all time, within 1y etc. \n",
    "\n",
    "Potentially: re-run with fault assumptions (no contributing factors on vehicle, not perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 1: Chance of Incident After Xth Violation\n",
    "\n",
    "This analysis looks at the year following a person's Xth violation and the chance, given the number of violations it is, they will get into an injury crash.\n",
    "\n",
    "To Do: \n",
    "\n",
    "- Remove people who were killed during the study period in one of the crashes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "drop table if exists working.all_vehicle_crashes; \n",
    "create table working.all_vehicle_crashes as \n",
    "\n",
    "select distinct \n",
    "\n",
    "    --CRASH INFO \n",
    "    a.crashid, \n",
    "    a.crash_date,\n",
    "    a.loc,\n",
    "    \n",
    "    --VEHICLE INFO \n",
    "    ve.vehicle_num, \n",
    "    replace(lower(ve.plate_num), ' ', '') plate_num, \n",
    "    \n",
    "    --DRIVER LICENSE NUM (Refined)\n",
    "    \n",
    "    --AGE OF DRIVER BUCKET \n",
    "    case \n",
    "        when dd.victim_age is null or dd.victim_age < 15 or dd.victim_age > 110 then 'Unknown' \n",
    "        when dd.victim_age between 15 and 29 then 'Young'\n",
    "        when dd.victim_age between 30 and 55 then 'Middle' \n",
    "        when dd.victim_age between 56 and 75 then 'Older' \n",
    "        when dd.victim_age between 76 and 110 then 'Very Old' \n",
    "    end as age,\n",
    "    \n",
    "    --SEX OF DRIVER \n",
    "    case \n",
    "        when dd.victim_sex is null then 'U'\n",
    "        else dd.victim_sex \n",
    "    end as sex,\n",
    "    \n",
    "    --TLC PLATE INDICATOR \n",
    "    tlc_veh, \n",
    "    \n",
    "    veh_type_general \n",
    "from \n",
    "    wc_accident_f a \n",
    "\n",
    "join \n",
    "    wc_accident_vehicle_f ve \n",
    "\n",
    "on \n",
    "    a.crashid=ve.crashid \n",
    "\n",
    "--GET DRIVER DEMO \n",
    "left join \n",
    "    working.driver_demo dd \n",
    "on \n",
    "    a.crashid=dd.crashid::numeric \n",
    "    and \n",
    "    replace(lower(ve.plate_num), ' ', '')=replace(lower(dd.plate_num), ' ', '')\n",
    "\n",
    "--NO TLC \n",
    "join \n",
    "    working.tlc_plate_ind tlc \n",
    "on \n",
    "    lower(ve.plate_num)=lower(tlc.plate_num)\n",
    "\n",
    "join \n",
    "    working.single_driver_plates pf \n",
    "on \n",
    "    replace(lower(ve.plate_num), ' ',  '')=pf.plate_num\n",
    "    \n",
    "--REMOVE JUNK PLATES \n",
    "join \n",
    "    working.cleaned_plates cp \n",
    "on \n",
    "    lower(ve.plate_num)=cp.plate_num \n",
    "\n",
    "where \n",
    "    --ONLY CRASHES 2017 ONWARDS \n",
    "    a.crash_date >= '2017-01-01'\n",
    "\n",
    "    --ONLY CARE ABOUT NY PLATES \n",
    "    and lower(ve.plate_state)='ny' \n",
    "\n",
    "    --LIMIT TO CAR/MCL/BUS \n",
    "    and ve.veh_type_general in ('car/suv') --, 'truck/bus', 'mcl')\n",
    "\n",
    "    --INJURY CRASHES \n",
    "    and a.crashid in (select crashid from wc_accident_victim_f)\n",
    "   \n",
    "    -- NO TLC VEHICLES \n",
    "    and not tlc_veh\n",
    "\n",
    "order by 1; \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded Speed Camera Violations \n",
    "- Returns the violations with past violation info (violations in prior year, prior two years, etc.)\n",
    "- Only limited to 2019 violations right now (for main violation, looks at huge universe for prior and after violations)\n",
    "\n",
    "REUSE CODE FOR RLC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "drop table if exists working.loaded_violations; \n",
    "create table working.loaded_violations as \n",
    "\n",
    "select distinct \n",
    "    v1.summons_number,\n",
    "    v1.plate,\n",
    "    v1.issue_date, \n",
    "    v1.violation_time, \n",
    "    v1.full_date,\n",
    "    max((v2.full_date between v1.full_date and v1.full_date::date + 365)::int) = 0 as vio_within_12_months, \n",
    "    count(distinct case when v2.full_date < v1.full_date and v2.full_date >= v1.full_date::date - 365 then v2.summons_number end) as prev_1y_violations, \n",
    "    count(distinct case when v2.full_date < v1.full_date and v2.full_date >= v1.full_date::date - 365 then v2.summons_number end) as prev_2y_violations, \n",
    "    count(distinct case when v2.full_date < v1.full_date and v2.full_date >= v1.full_date::date - 365 then v2.summons_number end) as prev_3y_violations, \n",
    "    count(distinct case when v2.full_date < v1.full_date then v2.summons_number end) as prev_all_violations \n",
    "from \n",
    "    working.speed_camera_vio v1\n",
    "left join\n",
    "    working.speed_camera_vio v2\n",
    "on \n",
    "    v1.plate=v2.plate\n",
    "    and v1.summons_number != v2.summons_number\n",
    "where\n",
    "    v1.issue_date >= '2019-01-01' \n",
    "    and v1.issue_date <= '2019-12-31'\n",
    "    and (v2.plate is null or v2.issue_date::date <= v1.issue_date::date + 365)\n",
    "    --LOWER? \n",
    "    and v1.state='NY'\n",
    "    and (v2.plate is null or v2.state='NY')\n",
    "    and v1.license_type = 'PAS'\n",
    "    and (v2.plate is null or v2.license_type = 'PAS')\n",
    "    and v1.full_date is not null \n",
    "group by \n",
    "    1, 2, 3, 4, 5; --, 6, 7;\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.3 Crash Loaded Violations \n",
    "\n",
    "- Returns the violation with associated crash info (within 12 months of violation)\n",
    "- Limited to 2019 crashes right now\n",
    "- DOES THAT DATE RANGE MAKE SENSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "drop table if exists working.crash_loaded_violations; \n",
    "create table working.crash_loaded_violations as \n",
    "\n",
    "with  all_loaded_crashes as (\n",
    "\n",
    "    select \n",
    "        lv.summons_number, lv.plate, array_agg(distinct ve.crashid) crashids \n",
    "\n",
    "    from \n",
    "        working.loaded_violations lv \n",
    "\n",
    "    join \n",
    "        working.all_vehicle_crashes ve \n",
    "\n",
    "    on \n",
    "        lower(lv.plate)=lower(ve.plate_num) \n",
    "        and ve.crash_date >= lv.full_date \n",
    "        and ve.crash_date <= lv.full_date::date + 365\n",
    "\n",
    "    where \n",
    "        ve.crash_date >= '2019-01-01'\n",
    "    \n",
    "    group by \n",
    "        1, 2\n",
    "\n",
    ")\n",
    "\n",
    "select distinct \n",
    "    lv.*, crashids\n",
    "\n",
    "from \n",
    "    working.loaded_violations lv \n",
    "\n",
    "join \n",
    "    all_loaded_crashes lc\n",
    "on \n",
    "    lv.summons_number=lc.summons_number \n",
    "    and \n",
    "    lower(lv.plate)=lower(lc.plate)\n",
    ";\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dfquery(\"\"\"\n",
    "\n",
    "select \n",
    "    * \n",
    "from\n",
    "    working.crash_loaded_violations\n",
    "limit 10 \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.4 Final Study \n",
    "\n",
    "Of those who received their xth violation within the past 12 mo, 24 mo within the study period, how many and what percent got into a crash? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = db.dfquery(\"\"\"\n",
    "\n",
    "with study_period_violations as (\n",
    "\n",
    "    select \n",
    "        summons_number, plate, full_date, prev_1y_violations, prev_1y_violations + 1 as violation_count \n",
    "    from \n",
    "        working.loaded_violations \n",
    "    where \n",
    "        issue_date between '2019-01-01' and '2019-12-31'\n",
    ")\n",
    "\n",
    "select \n",
    "    violation_count,\n",
    "    crash_ocurred, \n",
    "    count(*)\n",
    "from (\n",
    "    select distinct \n",
    "        spv.*, \n",
    "        case when clv.summons_number is not null then True else False end as Crash_Ocurred \n",
    "    \n",
    "    from \n",
    "        study_period_violations spv \n",
    "    \n",
    "    left join \n",
    "        working.crash_loaded_violations clv \n",
    "    \n",
    "    on \n",
    "        spv.summons_number=clv.summons_number \n",
    ") s  \n",
    "group by \n",
    "    1, 2\n",
    "order by 1 asc\n",
    "\n",
    "\"\"\").pivot(index='violation_count', columns='crash_ocurred', values='count').reset_index()\n",
    "\n",
    "study_df['%'] = study_df[True]/(study_df[True] + study_df[False])*100\n",
    "study_df['%'] = study_df['%'].round(2)\n",
    "\n",
    "study_df[study_df['violation_count'] <= 50].plot(x='violation_count', y='%') #.to_csv('Example.Csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df[study_df[False] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Study Design\n",
    "\n",
    "Looks at the maximum number of violations within a certain timeframe (ex. 2019) and the chance within that timeframe that cohort got into a crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = db.dfquery(\"\"\"\n",
    "\n",
    "with study_period_violations as (\n",
    "\n",
    "    select \n",
    "        summons_number, plate, full_date, prev_1y_violations, prev_1y_violations + 1 as violation_count \n",
    "    from \n",
    "        working.loaded_violations \n",
    "    where \n",
    "        issue_date between '2019-01-01' and '2019-12-31'\n",
    "\n",
    ")\n",
    "\n",
    "select \n",
    "    violation_count, crash_ocurred, count(*) \n",
    "from (\n",
    "    select \n",
    "        plate,\n",
    "        max(violation_count) as violation_count,\n",
    "        max(crash_ocurred::int)::boolean as crash_ocurred \n",
    "    from (\n",
    "        select distinct \n",
    "            spv.*, \n",
    "            case when clv.summons_number is not null then True else False end as Crash_Ocurred \n",
    "\n",
    "        from \n",
    "            study_period_violations spv \n",
    "\n",
    "        left join \n",
    "            working.crash_loaded_violations clv \n",
    "\n",
    "        on \n",
    "            spv.summons_number=clv.summons_number \n",
    "    ) s  \n",
    "    group by \n",
    "        1\n",
    ") p\n",
    "group by 1, 2\n",
    "\n",
    "\"\"\").pivot(index='violation_count', columns='crash_ocurred', values='count').reset_index()\n",
    "\n",
    "study_df['%'] = study_df[True]/(study_df[True] + study_df[False])*100\n",
    "study_df['%'] = study_df['%'].round(2)\n",
    "\n",
    "study_df[study_df['violation_count'] <= 30].plot(x='violation_count', y='%') #.to_csv('Example.Csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
